# -*- coding: utf-8 -*-
"""ConvNet MNIST

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-CeY1YY6PBCFwZZCm2ZPzYX_wNEW053u
"""

from keras.datasets import mnist

(train_images, train_labels), (test_images, test_lebels) = mnist.load_data()

"""# Transformando os dados
O objetivo agora será arrumar os dados para um padão que seja agradavel para o modelo ler e entender com facilidade

## Transformando as imagens
"""

print("Pixel de maior valor: {}".format(train_images.max()))

train_images = train_images/255
# train_images[0]

test_images = test_images / 255

"""Ajuda a salvar memória"""

train_images = train_images.astype('float32')
test_images = test_images.astype('float32')

"""##  Transformando as classes em vetores
A função `to_categorical()` irá fazer das classes dos números vetores. Cada classe um tipo de vetor diferente. Dessa maneira, o modelo irá funcionar, caso não seja aplicada a função, não existirá distinção entre as classes e o modeo não irá funcionar, retornando um erro.
"""

import tensorflow as tf

train_labels = tf.keras.utils.to_categorical(
    train_labels, num_classes=10)

test_lebels = tf.keras.utils.to_categorical(
    test_lebels, num_classes=10)

train_labels.shape

"""## Input shape
Como nosso plano é trabalhar com a `Conv2D()`, junto com imagens, temos que colocar nossos dados no *shape* correto. Como padrão, imagens tem o formato: $(n_i Imagens, Largura, Tamanho, Canais)$. Vamos então deixar nossas imagens nesse formato.
"""

train_images.shape

import numpy as np

train_images = train_images[:,:,:, np.newaxis]

train_images.shape

test_images = test_images[:,:,:, np.newaxis]

"""# Validation dataset
O objeivo nessa sessão será criar um validation dataset útil e aleatório
"""

import matplotlib.pyplot as plt

(train_i, train_l), (test_i, test_l) = mnist.load_data()

a = train_i
b = train_l

indices = np.arange(a.shape[0])
np.random.shuffle(indices)

a = a[indices]
b = b[indices]

plt.imshow(a[0])
plt.show()
print('Número: {}'.format(b[0]))

"""## Montando o validation dataset"""

train_images = train_images
train_labels = train_labels

indices = np.arange(train_images.shape[0])
np.random.shuffle(indices)

train_images = train_images[indices]
train_labels = train_labels[indices]

val_images = train_images[50000:]
val_labels = train_labels[50000:]

train_images = train_images[:50000]
train_labels = train_labels[:50000]

"""# Função melhor estruturada para o modelo"""

from keras import models
from keras import layers

def cria_modelo(optimizer="RMSprop", loss='categorical_crossentropy',
                metrics=['accuracy']):

    modelo = models.Sequential([
                                layers.Conv2D(16, (3,3), activation='relu',
                                              input_shape = (28, 28, 1)),
                                layers.MaxPooling2D((2,2)),
                                layers.Conv2D(32, (3,3), activation='relu'),
                                layers.MaxPooling2D(2,2),
                                layers.Conv2D(64, (3,3), activation='relu'),
                                layers.MaxPooling2D((2,2)),
                                layers.Flatten(),
                                layers.Dense(128, activation='relu'),
                                layers.Dense(10, activation='softmax')
    ])

    modelo.compile(optimizer=optimizer,
                  loss=loss,
                  metrics=metrics)
    
    return modelo

def treino_modelo(modelo, imagens, labels, validation_data,
                  batch_size=32, epochs=10):
    dados = modelo.fit(imagens, labels, batch_size, epochs, verbose=1,
               validation_data=validation_data)
    return dados

modelo = cria_modelo()
hist = treino_modelo(modelo, train_images, train_labels,
              validation_data=(val_images, val_labels))

"""# Analisando a performance do modelo"""

def plot_hist(value, value_val, label_value, label_val, title):

    epochs = range(1, len(value) + 1)

    plt.figure(figsize=(10,5))
    plt.grid(True)
    plt.title(title)

    plt.plot(epochs, value, 'bo', label=label_value)
    plt.plot(epochs, value_val, 'b', label=label_val)

    plt.legend()

    plt.show()

hist.history.keys()

val_loss = hist.history['val_loss']
val_accuracy = hist.history['val_accuracy']
loss = hist.history['loss']
accuracy = hist.history['accuracy']

plot_hist(accuracy, val_accuracy, 'Accuracy',
          'Val accuracy',
          'Accuracy and Val X eEpochs')
plot_hist(loss, val_loss, 'Loss', 'Val loss', 'Loss and Val X Epochs')

modelo.evaluate(test_images, test_lebels)

modelo.metrics_names